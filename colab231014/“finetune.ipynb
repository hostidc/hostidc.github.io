{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MriOV8kwGMfh"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ChatGLM-Tuning'...\n","remote: Enumerating objects: 163, done.\u001b[K\n","remote: Counting objects: 100% (108/108), done.\u001b[K\n","remote: Compressing objects: 100% (52/52), done.\u001b[K\n","remote: Total 163 (delta 72), reused 56 (delta 56), pack-reused 55\u001b[K\n","Receiving objects: 100% (163/163), 9.33 MiB | 10.71 MiB/s, done.\n","Resolving deltas: 100% (84/84), done.\n","/content/ChatGLM-Tuning/ChatGLM-Tuning\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 15))\n","  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-n_3rvl6h\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-n_3rvl6h\n","  Resolved https://github.com/huggingface/peft.git to commit 3714aa2fff158fdfa637b2b65952580801d890b2\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: bitsandbytes==0.37.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.37.1)\n","Requirement already satisfied: accelerate==0.17.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.17.1)\n","Requirement already satisfied: protobuf\u003c3.20.1,\u003e=3.19.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.20.0)\n","Requirement already satisfied: transformers==4.27.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.27.1)\n","Requirement already satisfied: icetk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.0.4)\n","Requirement already satisfied: cpm_kernels==1.0.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.0.11)\n","Requirement already satisfied: torch\u003e=1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.0.1+cu118)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.12.2)\n","Requirement already satisfied: datasets==2.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.10.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1-\u003e-r requirements.txt (line 3)) (1.22.4)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1-\u003e-r requirements.txt (line 3)) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1-\u003e-r requirements.txt (line 3)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1-\u003e-r requirements.txt (line 3)) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1-\u003e-r requirements.txt (line 7)) (3.12.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1-\u003e-r requirements.txt (line 7)) (0.14.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1-\u003e-r requirements.txt (line 7)) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1-\u003e-r requirements.txt (line 7)) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1-\u003e-r requirements.txt (line 7)) (0.13.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1-\u003e-r requirements.txt (line 7)) (4.65.0)\n","Requirement already satisfied: pyarrow\u003e=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (9.0.0)\n","Requirement already satisfied: dill\u003c0.3.7,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (0.70.14)\n","Requirement already satisfied: fsspec[http]\u003e=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (3.8.4)\n","Requirement already satisfied: responses\u003c0.19 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1-\u003e-r requirements.txt (line 14)) (0.18.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from icetk-\u003e-r requirements.txt (line 8)) (0.15.2+cu118)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from icetk-\u003e-r requirements.txt (line 8)) (0.1.99)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (16.0.5)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (1.54.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib\u003c1.1,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (1.0.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (3.4.3)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (1.8.1)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (2.3.0)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003e-r requirements.txt (line 11)) (0.40.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (23.1.0)\n","Requirement already satisfied: charset-normalizer\u003c4.0,\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (2.0.12)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (6.0.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (4.0.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (1.9.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (1.3.3)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (1.3.1)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003e-r requirements.txt (line 11)) (5.3.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003e-r requirements.txt (line 11)) (0.3.0)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003e-r requirements.txt (line 11)) (1.16.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003e-r requirements.txt (line 11)) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard-\u003e-r requirements.txt (line 11)) (1.3.1)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.27.1-\u003e-r requirements.txt (line 7)) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.27.1-\u003e-r requirements.txt (line 7)) (2022.12.7)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.27.1-\u003e-r requirements.txt (line 7)) (3.4)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard-\u003e-r requirements.txt (line 11)) (2.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets==2.10.1-\u003e-r requirements.txt (line 14)) (2022.7.1)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.13.1-\u003e-r requirements.txt (line 10)) (1.3.0)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-\u003eicetk-\u003e-r requirements.txt (line 8)) (8.4.0)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003e-r requirements.txt (line 11)) (0.5.0)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard-\u003e-r requirements.txt (line 11)) (3.2.2)\n"]}],"source":["!git clone https://github.com/mymusise/ChatGLM-Tuning.git\n","%cd  ChatGLM-Tuning\n","!pip install -r requirements.txt "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBnelqVNGMfj"},"outputs":[],"source":["!python cover_alpaca2jsonl.py \\\n","    --data_path data/alpaca_data.json \\\n","    --save_path data/alpaca_data.jsonl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zsOhTdaGMfj"},"outputs":[],"source":["!python tokenize_dataset_rows.py \\\n","    --jsonl_path data/alpaca_data.jsonl \\\n","    --save_path data/alpaca \\\n","    --max_seq_length 128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxuvbAMmGMfk"},"outputs":[],"source":["import sys\n","\n","sys.path.append(\"../\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELDQFY3sGMfk"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel, TrainingArguments, AutoConfig\n","import torch\n","import torch.nn as nn\n","from peft import get_peft_model, LoraConfig, TaskType\n","\n","\n","class CastOutputToFloat(nn.Sequential):\n","    def forward(self, x): return super().forward(x).to(torch.float32)\n","\n","\n","model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", load_in_8bit=True, trust_remote_code=True, device_map='auto')\n","model.supports_gradient_checkpointing = True\n","model.gradient_checkpointing_enable()\n","model.enable_input_require_grads()\n","model.lm_head = CastOutputToFloat(model.lm_head)\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYxwSwGiGMfl"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)"]},{"cell_type":"markdown","metadata":{"id":"p0FS8xdwGMfm"},"source":["## Test before finetune"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWttnCMtGMfn"},"outputs":[],"source":["from cover_alpaca2jsonl import format_example\n","import json\n","\n","\n","instructions = json.load(open(\"data/alpaca_data.json\"))\n","\n","\n","with torch.no_grad():\n","    for idx, item in enumerate(instructions[:5]):\n","        feature = format_example(item)\n","        input_text = feature[\"context\"]\n","        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","        out = model.generate(\n","            input_ids=input_ids,\n","            max_length=150,\n","            temperature=0\n","        )\n","        answer = tokenizer.decode(out[0])\n","        print(answer)\n","        item['infer_answer'] = answer\n","        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7ttm6ybGMfo"},"outputs":[],"source":["peft_config = LoraConfig(\n","    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n","    r=8,\n","    lora_alpha=32, lora_dropout=0.1,\n",")\n","\n","model = get_peft_model(model, peft_config)\n","model.is_parallelizable = True\n","model.model_parallel = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FViJDUgGMfp"},"outputs":[],"source":["import datasets\n","\n","dataset_path = \"data/alpaca/\"\n","\n","dataset = datasets.load_from_disk(dataset_path)\n","\n","train_num = 500\n","\n","mini_train_dataset = datasets.Dataset.from_dict(dataset[:train_num])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JP_mj7qMGMfp"},"outputs":[],"source":["from transformers import Trainer, HfArgumentParser\n","\n","\n","def data_collator(features: list) -\u003e dict:\n","    len_ids = [len(feature[\"input_ids\"]) for feature in features]\n","    longest = max(len_ids)\n","    input_ids = []\n","    labels_list = []\n","    for ids_l, feature in sorted(zip(len_ids, features), key=lambda x: -x[0]):\n","        ids = feature[\"input_ids\"]\n","        seq_len = feature[\"seq_len\"]\n","        labels = (\n","            [-100] * (seq_len - 1) + ids[(seq_len - 1) :] + [-100] * (longest - ids_l)\n","        )\n","        ids = ids + [tokenizer.pad_token_id] * (longest - ids_l)\n","        _ids = torch.LongTensor(ids)\n","        labels_list.append(torch.LongTensor(labels))\n","        input_ids.append(_ids)\n","    input_ids = torch.stack(input_ids)\n","    labels = torch.stack(labels_list)\n","    return {\n","        \"input_ids\": input_ids,\n","        \"labels\": labels,\n","    }\n","\n","class ModifiedTrainer(Trainer):\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        return model(\n","            input_ids=inputs[\"input_ids\"],\n","            labels=inputs[\"labels\"],\n","        ).loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeGiLKcOGMfq"},"outputs":[],"source":["training_args = TrainingArguments(\n","    \"output\",\n","    fp16 =True,\n","    gradient_accumulation_steps=1,\n","    per_device_train_batch_size = 1,\n","    learning_rate = 1e-4,\n","    max_steps=1500,\n","    logging_steps=50,\n","    remove_unused_columns=False,\n","    seed=0,\n","    data_seed=0,\n","    group_by_length=False,\n",")\n","\n","\n","trainer = ModifiedTrainer(\n","    model=model,\n","    train_dataset=mini_train_dataset,\n","    args=training_args,\n","    data_collator=data_collator,\n",")\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"kQkOBDIgGMfr"},"source":["## Test After finetune"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6wT-_-YGMfr"},"outputs":[],"source":["from cover_alpaca2jsonl import format_example\n","import json\n","\n","\n","instructions = json.load(open(\"data/alpaca_data.json\"))\n","\n","\n","with torch.no_grad():\n","    for idx, item in enumerate(instructions[:5]):\n","        feature = format_example(item)\n","        input_text = feature[\"context\"]\n","        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","        out = model.generate(\n","            input_ids=input_ids,\n","            max_length=150,\n","            temperature=0\n","        )\n","        answer = tokenizer.decode(out[0])\n","        print(answer)\n","        item['infer_answer'] = answer\n","        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FA1LM-D8GMfr"},"outputs":[],"source":["import os\n","\n","\n","def save_tunable_parameters(model, path):\n","    saved_params = {\n","        k: v.to(\"cpu\")\n","        for k, v in model.named_parameters()\n","        if v.requires_grad\n","    }\n","    torch.save(saved_params, path)\n","\n","\n","save_tunable_parameters(model, os.path.join(\"output\", \"chatglm-lora.pt\"))"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"https://github.com/mymusise/ChatGLM-Tuning/blob/master/examples/finetune.ipynb","timestamp":1684987768313}],"version":""},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12 (default, Feb  7 2022, 13:32:35) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"}}},"nbformat":4,"nbformat_minor":0}